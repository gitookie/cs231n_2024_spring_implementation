# RNN_Captioning部分

## 流程：

### 1.简单介绍一下Image Captioning是什么，还有介绍了COCO数据集

### 2.实现rnn中一个时间步的前向和后向传播，之后把它们堆起来，实现rnn中全部的前向传播和后向传播。因为中间的每个时间步的输入是caption的一部分，有一个从idx到vector的转换，需要一个word embedding层（也就是进行一个查询操作），故这里也需要实现一下前向和后向传播。最后的输出是由隐状态，经过一个affine layer再进行分类，得到预测的idx，再用idx，查询corpus得到输出的caption。最后这里其实就类似前面实现过的softmax分类，故不用再重复实现

### 3.实现CaptioningRNN类，包括实现loss函数和sample函数。loss函数就是求出损失和梯度，利用前面实现过的层，理清前向的逻辑，后向就比较容易了。sample函数是测试的时候用的，效果就是，传入一幅图像的特征，输出对这幅图像的描述。大体的前向逻辑是一样的，最后输出也是，用隐状态输出预测的分类，只不过不需要求梯度了

# Transformer Captioning部分

## 流程：

### 1.先实现前向的多头注意力和position encoding。因为这里是用pytorch，所以不需要自己写反向传播的部分了。多头注意力的实现主要涉及几个地方：.view和.moveaxis之类的操作；当key和query的seq len不相等时应该怎么处理（需要移动维度，以便进行张量乘法）；mask的构造。position encoding的话，理解了原理就还好，然后实现的话主要是要想到一些广播的机制

### 2.实现整个captioning_transformer类。它的前向过程的重点在于调用transformer_decoder类，而这个类又在调用之前实现过的多头注意力的层，本质还是看前面的多头注意力的实现和接口

### 3.最后就是训一个模型，看看它的效果。反正在训练集上过拟合是很轻松的，最后的损失也是比RNN的要低，说明模型性能还行，不过没怎么调泛化性，在验证集上很差

# Self_Supervised_Learning部分

## 流程：

### 1.先介绍了一下自监督学习的重要性，然后引入一种对比学习的方法：SimCLR，讲了一下其大概方法：任取一个样本，对其进行数据增强，得到两份数据，用一个网络对这两份数据进行变换（也就是一个encoder），最后再进行一个projection，得到两个向量，我们希望让这两个向量尽可能相似。这样训练下来，得到的第一个变换的网络encoder，就可以比较好地提取数据的特征，可用于下游任务

### 2.实现data augmentation（主要用到torchvision的transform的各种函数），看懂它的encoder和projection的架构，

### 3.接着是实现核心部分：对比损失。它的定义还是比较简单的，就是注意每两个样本之间的对比损失是非对称的，所以计算一个batch的损失的时候，要遍历这2N个数据。朴素实现就按照定义写循环就好。向量化的话，要点就是分别向量化地求出损失的分子和分母。分子每对positive pair之间的相似度，很好求；分母比较麻烦的是，我们不考虑每个样本和它自己的相似度，所以要剔除掉，这里会用到一些mask和masked_select函数。容易漏的细节主要是keepdim=True，以及tau不能忘。最后trian函数的实现，它已经给了主体代码了，我们要做的也只是调个模型而已。通过对比有自监督和没有自监督的两个模型（同一个架构）

### 4.

# Generative_Adversarial_Networks部分

## 流程：

### 1.首先介绍了一下gan，然后讲解了一下它的组合和损失函数，并粗略展示了vanilla gan，ls gan，dcgan的效果，效果依次递增

### 2.逐个实现三种gan。它们的主体都是由discriminator和generator组成，区别只是损失函数而后两个部件的网络结构

### 3.后面是一些思考，主要想说明的就是，gan比较健康的训练状态是，discriminator和generator交替着提升，并且一方不能落后另一方太多，否则可能有一个损失光降了，但是效果完全没提升，此时已经是无效训练了

# LSTM_Captioning部分

## 流程：

### 其实跟RNN_Captioning的完全一样，只是省去了介绍部分。事实上，LSTM只是RNN的一种变体，大体流程是不变的。只不过在一个Captioning_RNN类里实现可选的rnn/lstm时，注意二者需要的参数不太一样，以及lstm会引入cell state，参数会多一个。剩下基本一样。

### 具体实现上，它相比于朴素rnn，主要是多了一个“控制项”，即tanh(next_c)，这个next_c即所谓cell state。而cell state的计算又引入了所谓“遗忘门”“输入门”机制，讲故事上倒是挺好的，实际效果就不好说了。感觉它之所以能缓解一些长程依赖的问题，只是因为多了一个支路，即cell state支路，而cell stae支路也蕴含了一些历史信息，再加上h也有一些历史信息，保存的内容可能相比朴素rnn会多些。但代价也是付出更多的计算量（相比于朴素rnn）（虽然量级也还是一样的）

### 另外，实现时，激活函数最好还是用官方库里的，数值稳定性之类的都比较有保障。自己实现的很容易出现训练时loss的nan。（另：sigmoid的实现的数值稳定倒是比较好实现的，它的主要问题是如果有很负的元素，计算时就会遇到很大的正数出现在e的指数位置上，避免这一点即可）（而tanh的实现就没那么简单了，按它的定义，只要有绝对值很大的元素，就一定会出现很大的正数成为指数的情况。可能得讨论正负，例如，对于正数，就将$\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$上下同除以$e^{x}$，得到$\frac{1-e^{-2x}}{1+e^{-2x}}$，这时就不会有很大的正数出现在指数位置上了；而对于负数，容易想到上下同除以$e^{-x}$。显然，整体的实现会麻烦一些，可能用到一些mask。甚至可能还有其它问题，需要用到其它算法，所以一般还是老老实实用库的函数吧

